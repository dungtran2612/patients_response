{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version()) # check python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa517360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# library version\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10361873",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with pandas\n",
    "data = pd.read_csv(input_dir +'pheno_met.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e62c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Min_Cortisol_Group'] = data['Cortisol'] > 18\n",
    "data['Min_Cortisol_Group']\n",
    "data['Min_Cortisol_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the input columns in the list input_cols: \n",
    "# M100022013: tetrahydrocortisol glucuronide; M100022127: tetrahydrocortisone glucuronide (5); M100000963: homocitrulline\n",
    "input_cols = ['M100022013','M100022127','M100000963','all']\n",
    "\n",
    "# put target name in target variable\n",
    "target = 'Min_Cortisol_Group'\n",
    "\n",
    "####run models\n",
    "#import\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#result list\n",
    "results = []\n",
    "\n",
    "#loop 10 runs with set seeds\n",
    "for seed in [111, 222, 333, 444, 555, 666, 777, 888, 999, 101]:\n",
    "    #set seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #train test split\n",
    "    train_data, test_data = train_test_split(data, test_size = 0.2)\n",
    "    \n",
    "    #loop through metabolite\n",
    "    for met in input_cols:\n",
    "        if met != 'all':\n",
    "            input_list = [met]\n",
    "        else:\n",
    "            input_list = ['M100022013','M100022127','M100000963']\n",
    "        processing_pipeline = ColumnTransformer([(\"selector\", \"passthrough\", input_list)], remainder=\"drop\")\n",
    "        \n",
    "        #logistic\n",
    "        logistic = LogisticRegression(max_iter=10000)\n",
    "        param_grid = [{'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1 , 5, 10, 50, 100]}]\n",
    "        grid_search = GridSearchCV(logistic, param_grid, cv=5, scoring='roc_auc', return_train_score=True)\n",
    "\n",
    "        logistic_pipeline = Pipeline([\n",
    "            ('processing', processing_pipeline),\n",
    "            ('modeling', grid_search)\n",
    "        ])\n",
    "\n",
    "        logistic_pipeline.fit(train_data, train_data[target])\n",
    "        logistic_train_auc = logistic_pipeline['modeling'].best_score_\n",
    "        logistic_test_auc = logistic_pipeline.score(test_data, test_data[target])\n",
    "        \n",
    "        #SVM\n",
    "        svc = SVC()\n",
    "        param_grid = [{\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'kernel' : ['rbf'],\n",
    "            'gamma' : [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "        }]\n",
    "\n",
    "        grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='roc_auc', return_train_score=True)\n",
    "\n",
    "        svc_pipeline = Pipeline([\n",
    "            ('processing', processing_pipeline),\n",
    "            ('modeling', grid_search)\n",
    "        ])\n",
    "\n",
    "        svc_pipeline.fit(train_data[:2000], train_data[target][:2000])\n",
    "        svc_train_auc = svc_pipeline['modeling'].best_score_\n",
    "        svc_test_auc = svc_pipeline.score(test_data, test_data[target])\n",
    "        \n",
    "        #RF\n",
    "        param_grid = [{\n",
    "            'max_depth': [3, 4, 5, 6],\n",
    "            'min_samples_split' : [0.05, 0.1, 0.2],\n",
    "            'min_samples_leaf' : [0.05, 0.1, 0.2],\n",
    "            'n_estimators': [10, 20, 50, 100]\n",
    "        }]\n",
    "\n",
    "        forest = RandomForestClassifier()\n",
    "\n",
    "        grid_search = GridSearchCV(forest, param_grid, cv=5, scoring='roc_auc', return_train_score=True)\n",
    "\n",
    "        forest_pipeline = Pipeline([\n",
    "            ('processing', processing_pipeline),\n",
    "            ('modeling', grid_search)\n",
    "        ])\n",
    "\n",
    "        forest_pipeline.fit(train_data, train_data[target])\n",
    "        forest_train_auc = forest_pipeline['modeling'].best_score_\n",
    "        forest_test_auc = forest_pipeline.score(test_data, test_data[target])\n",
    "        \n",
    "        #GB (use same parameter grid with RF, so no needs to redefine)\n",
    "        gbc = GradientBoostingClassifier()\n",
    "\n",
    "        grid_search = GridSearchCV(gbc, param_grid, cv=5, scoring='roc_auc', return_train_score=True)\n",
    "\n",
    "        gbc_pipeline = Pipeline([\n",
    "            ('processing', processing_pipeline),\n",
    "            ('modeling', grid_search)\n",
    "        ])\n",
    "\n",
    "        gbc_pipeline.fit(train_data, train_data[target])\n",
    "        gbc_train_auc = gbc_pipeline['modeling'].best_score_\n",
    "        gbc_test_auc = gbc_pipeline.score(test_data, test_data[target])\n",
    "        \n",
    "        #MLP\n",
    "        n_features = len(input_cols)\n",
    "\n",
    "        param_grid = [{\n",
    "            'hidden_layer_sizes' : [[n_features // 2, n_features // 2],\n",
    "                                    [n_features // 2, n_features // 2, n_features // 2],\n",
    "                                    [n_features, n_features],\n",
    "                                    [n_features, n_features, n_features],\n",
    "                                    [n_features*2, n_features*2],\n",
    "                                    [n_features*2, n_features*2, n_features*2]],\n",
    "            'alpha' : [0.001, 0.01, 0.1, 1, 10]                                    #regularization terms\n",
    "        }]\n",
    "\n",
    "        mlp = MLPClassifier(max_iter=10000)\n",
    "        grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='roc_auc', return_train_score=True)\n",
    "\n",
    "        mlp_pipeline = Pipeline([\n",
    "            ('processing', processing_pipeline),\n",
    "            ('modeling', grid_search)\n",
    "        ])\n",
    "\n",
    "        mlp_pipeline.fit(train_data, train_data[target])\n",
    "        mlp_train_auc = mlp_pipeline['modeling'].best_score_\n",
    "        mlp_test_auc = mlp_pipeline.score(test_data, test_data[target])\n",
    "        results.append([seed, met, \n",
    "                        logistic_train_auc,\n",
    "                        logistic_test_auc,\n",
    "                        svc_train_auc,\n",
    "                        svc_test_auc,\n",
    "                        forest_train_auc,\n",
    "                        forest_test_auc,\n",
    "                        gbc_train_auc,\n",
    "                        gbc_test_auc,\n",
    "                        mlp_train_auc,\n",
    "                        mlp_test_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ea3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['seed', 'metabolite', \n",
    "                      'logistic_train_auc',\n",
    "                      'logistic_test_auc',\n",
    "                      'svc_train_auc',\n",
    "                      'svc_test_auc',\n",
    "                      'forest_train_auc',\n",
    "                      'forest_test_auc',\n",
    "                      'gbc_train_auc',\n",
    "                      'gbc_test_auc',\n",
    "                      'mlp_train_auc',\n",
    "                      'mlp_test_auc']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '...'\n",
    "results_df.to_csv(output_dir + 'Prediction_model_result_of_validated_sig_metabolites.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6da5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b731d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Jupyter Conda Test Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
